{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lIs44WAMDl_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcdfb371-655a-4606-979f-1310fb81bbba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_xla/__init__.py:202: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn, Tensor\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets import CIFAR100\n",
        "import pandas as pd\n",
        "from torchvision.transforms import v2\n",
        "from torch.backends import cudnn\n",
        "from torch import GradScaler\n",
        "from torch import optim\n",
        "from tqdm import tqdm\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "from torch_xla.amp import GradScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device('cuda')\n",
        "# cudnn.benchmark = True\n",
        "pin_memory = True\n",
        "device = xm.xla_device()\n",
        "enable_half = True  # Disable for CPU, it is slower!\n",
        "scaler = GradScaler()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMlRV4fjJQ5b",
        "outputId": "525692c6-93b1-4fdf-b3f1-ca2800f723ef"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_xla/amp/grad_scaler.py:36: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  super().__init__(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCachedDataset(Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        # Runtime transforms are not implemented in this simple cached dataset.\n",
        "        self.data = tuple([x for x in dataset])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.data[i]"
      ],
      "metadata": {
        "id": "OcxcgcXpJVk9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basic_transforms = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize((0.5, 0.5, 0.5), (0.25, 0.25, 0.25), inplace=True)\n",
        "])\n",
        "train_set = CIFAR100('/kaggle/input/fii-atnn-2024-assignment-2', download=True, train=True, transform=basic_transforms)\n",
        "test_set = CIFAR100('/kaggle/input/fii-atnn-2024-assignment-2', download=True, train=False, transform=basic_transforms)\n",
        "train_set = SimpleCachedDataset(train_set)\n",
        "test_set = SimpleCachedDataset(test_set)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, pin_memory=pin_memory)\n",
        "test_loader = DataLoader(test_set, batch_size=500, pin_memory=pin_memory)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1QnCtWOJcR_",
        "outputId": "16124bac-a934-4357-e30b-b0edaa96d770"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG16, self).__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Block 2\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Block 3\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Block 4\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Block 5\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Classifier\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512, 100)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self.layers(x)\n"
      ],
      "metadata": {
        "id": "BS4Z5JyTJx50"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG16().to(device)\n",
        "model = torch.jit.script(model)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.005)"
      ],
      "metadata": {
        "id": "djTwD0xAJzwd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
        "        with torch.autocast(device.type, enabled=enable_half):\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        predicted = outputs.argmax(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    return 100.0 * correct / total"
      ],
      "metadata": {
        "id": "vt0lX8j2Padb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.inference_mode()\n",
        "def val():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
        "        with torch.autocast(device.type, enabled=enable_half):\n",
        "            outputs = model(inputs)\n",
        "\n",
        "        predicted = outputs.argmax(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    return 100.0 * correct / total"
      ],
      "metadata": {
        "id": "j9yUT1JmPc_k"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.inference_mode()\n",
        "def inference():\n",
        "    model.eval()\n",
        "\n",
        "    labels = []\n",
        "\n",
        "    for inputs, _ in test_loader:\n",
        "        inputs = inputs.to(device, non_blocking=True)\n",
        "        with torch.autocast(device.type, enabled=enable_half):\n",
        "            outputs = model(inputs)\n",
        "\n",
        "        predicted = outputs.argmax(1).tolist()\n",
        "        labels.extend(predicted)\n",
        "\n",
        "    return labels"
      ],
      "metadata": {
        "id": "SG3Zpv1OPkmw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best = 0.0\n",
        "epochs = list(range(50))\n",
        "with tqdm(epochs) as tbar:\n",
        "    for epoch in tbar:\n",
        "        train_acc = train()\n",
        "        val_acc = val()\n",
        "        if val_acc > best:\n",
        "            best = val_acc\n",
        "        tbar.set_description(f\"Train: {train_acc:.2f}, Val: {val_acc:.2f}, Best: {best:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awCcaOm5PmAC",
        "outputId": "a60a9e38-7b9d-408f-a962-32f602c1bee5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 96.74, Val: 51.64, Best: 51.64: 100%|██████████| 50/50 [1:39:33<00:00, 119.47s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"ID\": [],\n",
        "    \"target\": []\n",
        "}\n",
        "\n",
        "\n",
        "for i, label in enumerate(inference()):\n",
        "    data[\"ID\"].append(i)\n",
        "    data[\"target\"].append(label)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "6D3aFqBxoUxO"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}