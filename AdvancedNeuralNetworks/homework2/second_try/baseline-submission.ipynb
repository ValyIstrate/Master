{
    "metadata": {
        "kernelspec": {
            "language": "python",
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.15",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kaggle": {
            "accelerator": "tpu1vmV38",
            "dataSources": [
                {
                    "sourceId": 85904,
                    "databundleVersionId": 9723326,
                    "sourceType": "competition"
                }
            ],
            "dockerImageVersionId": 30775,
            "isInternetEnabled": false,
            "language": "python",
            "sourceType": "notebook",
            "isGpuEnabled": false
        }
    },
    "nbformat_minor": 4,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "code",
            "source": "import torch\nfrom torch import nn, Tensor\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.datasets import CIFAR100\nimport pandas as pd\nfrom torchvision.transforms import v2\nfrom torch.backends import cudnn\nfrom torch import GradScaler\nfrom torch import optim\nfrom tqdm import tqdm\nimport torch_xla\nimport torch_xla.core.xla_model as xm\nfrom torch_xla.amp import GradScaler",
            "metadata": {
                "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
                "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
                "execution": {
                    "iopub.status.busy": "2024-10-15T12:37:53.629899Z",
                    "iopub.execute_input": "2024-10-15T12:37:53.630146Z",
                    "iopub.status.idle": "2024-10-15T12:37:53.638907Z",
                    "shell.execute_reply.started": "2024-10-15T12:37:53.630116Z",
                    "shell.execute_reply": "2024-10-15T12:37:53.638282Z"
                },
                "trusted": true
            },
            "execution_count": 5,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "# device = torch.device('cuda')\n# print(torch.cuda.is_available())\n# cudnn.benchmark = True\n# pin_memory = True\n# enable_half = True  # Disable for CPU, it is slower!\n# scaler = GradScaler(device, enabled=enable_half)\n# device = torch.device('cuda')\n# cudnn.benchmark = True\npin_memory = True\ndevice = xm.xla_device()\nenable_half = True  # Disable for CPU, it is slower!\nscaler = GradScaler()",
            "metadata": {
                "execution": {
                    "iopub.status.busy": "2024-10-15T12:37:53.639693Z",
                    "iopub.execute_input": "2024-10-15T12:37:53.639912Z",
                    "iopub.status.idle": "2024-10-15T12:37:53.648654Z",
                    "shell.execute_reply.started": "2024-10-15T12:37:53.639889Z",
                    "shell.execute_reply": "2024-10-15T12:37:53.648001Z"
                },
                "trusted": true
            },
            "execution_count": 6,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "class SimpleCachedDataset(Dataset):\n    def __init__(self, dataset):\n        # Runtime transforms are not implemented in this simple cached dataset.\n        self.data = tuple([x for x in dataset])\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, i):\n        return self.data[i]\n",
            "metadata": {
                "execution": {
                    "iopub.status.busy": "2024-10-15T12:37:53.649432Z",
                    "iopub.execute_input": "2024-10-15T12:37:53.649656Z",
                    "iopub.status.idle": "2024-10-15T12:37:53.660785Z",
                    "shell.execute_reply.started": "2024-10-15T12:37:53.649634Z",
                    "shell.execute_reply": "2024-10-15T12:37:53.660132Z"
                },
                "trusted": true
            },
            "execution_count": 7,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "basic_transforms = v2.Compose([\n    v2.ToImage(),\n    v2.ToDtype(torch.float32, scale=True),\n    v2.Normalize((0.5, 0.5, 0.5), (0.25, 0.25, 0.25), inplace=True)\n])\ntrain_set = CIFAR100('/kaggle/input/fii-atnn-2024-assignment-2', download=False, train=True, transform=basic_transforms)\ntest_set = CIFAR100('/kaggle/input/fii-atnn-2024-assignment-2', download=False, train=False, transform=basic_transforms)\ntrain_set = SimpleCachedDataset(train_set)\ntest_set = SimpleCachedDataset(test_set)\n\ntrain_loader = DataLoader(train_set, batch_size=64, shuffle=True, pin_memory=pin_memory)\ntest_loader = DataLoader(test_set, batch_size=500, pin_memory=pin_memory)\n",
            "metadata": {
                "execution": {
                    "iopub.status.busy": "2024-10-15T12:37:53.661604Z",
                    "iopub.execute_input": "2024-10-15T12:37:53.661823Z",
                    "iopub.status.idle": "2024-10-15T12:38:13.580713Z",
                    "shell.execute_reply.started": "2024-10-15T12:37:53.661801Z",
                    "shell.execute_reply": "2024-10-15T12:38:13.579854Z"
                },
                "trusted": true
            },
            "execution_count": 8,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "class VGG16(nn.Module):\n    def __init__(self):\n        super(VGG16, self).__init__()\n\n        self.layers = nn.Sequential(\n            # Block 1\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            # Block 2\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            # Block 3\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            # Block 4\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            # Block 5\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            # Classifier\n            nn.Flatten(),\n            nn.Linear(512, 100)\n        )\n\n    def forward(self, x: Tensor) -> Tensor:\n        return self.layers(x)\n",
            "metadata": {
                "execution": {
                    "iopub.status.busy": "2024-10-15T12:38:13.581785Z",
                    "iopub.execute_input": "2024-10-15T12:38:13.582043Z",
                    "iopub.status.idle": "2024-10-15T12:38:13.593245Z",
                    "shell.execute_reply.started": "2024-10-15T12:38:13.582019Z",
                    "shell.execute_reply": "2024-10-15T12:38:13.592561Z"
                },
                "trusted": true
            },
            "execution_count": 9,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "model = VGG16().to(device)\nmodel = torch.jit.script(model)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adagrad(model.parameters(), lr=0.01)\n",
            "metadata": {
                "execution": {
                    "iopub.status.busy": "2024-10-15T12:38:13.594075Z",
                    "iopub.execute_input": "2024-10-15T12:38:13.594312Z",
                    "iopub.status.idle": "2024-10-15T12:38:13.947324Z",
                    "shell.execute_reply.started": "2024-10-15T12:38:13.594289Z",
                    "shell.execute_reply": "2024-10-15T12:38:13.946427Z"
                },
                "trusted": true
            },
            "execution_count": 10,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "def train():\n    model.train()\n    correct = 0\n    total = 0\n    \n    for inputs, targets in train_loader:\n        inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n        with torch.autocast(device.type, enabled=enable_half):\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad()\n\n        predicted = outputs.argmax(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n    \n    return 100.0 * correct / total",
            "metadata": {
                "execution": {
                    "iopub.status.busy": "2024-10-15T12:38:13.949438Z",
                    "iopub.execute_input": "2024-10-15T12:38:13.949695Z",
                    "iopub.status.idle": "2024-10-15T12:38:13.955195Z",
                    "shell.execute_reply.started": "2024-10-15T12:38:13.949671Z",
                    "shell.execute_reply": "2024-10-15T12:38:13.954343Z"
                },
                "trusted": true
            },
            "execution_count": 11,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "@torch.inference_mode()\ndef val():\n    model.eval()\n    correct = 0\n    total = 0\n\n    for inputs, targets in test_loader:\n        inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n        with torch.autocast(device.type, enabled=enable_half):\n            outputs = model(inputs)\n\n        predicted = outputs.argmax(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n    \n    return 100.0 * correct / total",
            "metadata": {
                "execution": {
                    "iopub.status.busy": "2024-10-15T12:38:13.956125Z",
                    "iopub.execute_input": "2024-10-15T12:38:13.956408Z",
                    "iopub.status.idle": "2024-10-15T12:38:13.969049Z",
                    "shell.execute_reply.started": "2024-10-15T12:38:13.956360Z",
                    "shell.execute_reply": "2024-10-15T12:38:13.968412Z"
                },
                "trusted": true
            },
            "execution_count": 12,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "@torch.inference_mode()\ndef inference():\n    model.eval()\n    \n    labels = []\n    \n    for inputs, _ in test_loader:\n        inputs = inputs.to(device, non_blocking=True)\n        with torch.autocast(device.type, enabled=enable_half):\n            outputs = model(inputs)\n\n        predicted = outputs.argmax(1).tolist()\n        labels.extend(predicted)\n    \n    return labels",
            "metadata": {
                "execution": {
                    "iopub.status.busy": "2024-10-15T12:38:13.969911Z",
                    "iopub.execute_input": "2024-10-15T12:38:13.970143Z",
                    "iopub.status.idle": "2024-10-15T12:38:13.979794Z",
                    "shell.execute_reply.started": "2024-10-15T12:38:13.970119Z",
                    "shell.execute_reply": "2024-10-15T12:38:13.979164Z"
                },
                "trusted": true
            },
            "execution_count": 13,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "best = 0.0\nepochs = list(range(50))\nwith tqdm(epochs) as tbar:\n    for epoch in tbar:\n        train_acc = train()\n        val_acc = val()\n        if val_acc > best:\n            best = val_acc\n        tbar.set_description(f\"Train: {train_acc:.2f}, Val: {val_acc:.2f}, Best: {best:.2f}\")",
            "metadata": {
                "execution": {
                    "iopub.status.busy": "2024-10-15T12:38:13.980578Z",
                    "iopub.execute_input": "2024-10-15T12:38:13.980800Z",
                    "iopub.status.idle": "2024-10-15T13:30:19.084917Z",
                    "shell.execute_reply.started": "2024-10-15T12:38:13.980777Z",
                    "shell.execute_reply": "2024-10-15T13:30:19.083844Z"
                },
                "trusted": true
            },
            "execution_count": 14,
            "outputs": [
                {
                    "name": "stderr",
                    "text": "Train: 99.95, Val: 49.87, Best: 52.37: 100%|██████████| 50/50 [52:05<00:00, 62.50s/it]\n",
                    "output_type": "stream"
                }
            ]
        },
        {
            "cell_type": "code",
            "source": "data = {\n    \"ID\": [],\n    \"target\": []\n}\n\n\nfor i, label in enumerate(inference()):\n    data[\"ID\"].append(i)\n    data[\"target\"].append(label)\n\ndf = pd.DataFrame(data)\ndf.to_csv(\"/kaggle/working/submission.csv\", index=False)",
            "metadata": {
                "execution": {
                    "iopub.status.busy": "2024-10-15T13:30:19.086220Z",
                    "iopub.execute_input": "2024-10-15T13:30:19.086545Z",
                    "iopub.status.idle": "2024-10-15T13:30:29.721012Z",
                    "shell.execute_reply.started": "2024-10-15T13:30:19.086517Z",
                    "shell.execute_reply": "2024-10-15T13:30:29.719938Z"
                },
                "trusted": true
            },
            "execution_count": 15,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "",
            "metadata": {},
            "execution_count": null,
            "outputs": []
        }
    ]
}