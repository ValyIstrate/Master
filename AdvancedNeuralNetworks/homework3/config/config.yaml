model:
  name: "mlp"
  num_classes: 10

dataset:
  name: "MNIST"
  path: "./data"
  batch_size: 64
  num_workers: 4
  augmentation: "basic"
  pin_memory: true

training:
  device: "cuda"
  epochs: 1
  early_stopping: 5
  optimizer: "Adam"
  learning_rate: 0.001
  scheduler: "StepLR"
  scheduler_params:
    step_size: 10
    gamma: 0.1

logging:
  tensorboard_log_dir: "runs/tensorboard"
  wandb_project_name: "Training Pipeline"
  use_tensorboard: true
  use_wandb: true
